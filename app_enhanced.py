import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Tuple
import time
import random
import json
import uuid
import os
import re
from urllib.parse import urlencode, quote
import gc
from streamlit.errors import StreamlitAPIException, StreamlitSecretNotFoundError

# ç‚ºå…è²»æ–¹æ¡ˆè¨­å®šé™åˆ¶
MAX_HISTORY_ITEMS = 20
MAX_FAVORITE_ITEMS = 40
MAX_BATCH_SIZE = 4

# åœ–åƒå°ºå¯¸é è¨­
IMAGE_SIZES = {
    "è‡ªå®šç¾©...": "Custom", 
    "512x512": "SD æ¨™æº– (1:1)", 
    "768x768": "SD XL æ¨™æº– (1:1)",
    "1024x1024": "æ­£æ–¹å½¢ (1:1)", 
    "1080x1080": "IG è²¼æ–‡ (1:1)",
    "512x768": "SD ç¸±å‘ (2:3)",
    "768x512": "SD æ©«å‘ (3:2)",
    "1080x1350": "IG ç¸±å‘ (4:5)", 
    "1080x1920": "IG Story (9:16)", 
    "1200x630": "FB æ©«å‘ (1.91:1)",
    "1536x640": "è¶…å¯¬æ©«å¹… (2.4:1)",
    "896x1152": "è‚–åƒæ¨¡å¼ (7:9)",
    "1152x896": "é¢¨æ™¯æ¨¡å¼ (9:7)",
}

# æ“´å±•é¢¨æ ¼é è¨­
STYLE_PRESETS = {
    # åŸºç¤é¢¨æ ¼
    "ç„¡": "", 
    "é›»å½±æ„Ÿ": "cinematic, dramatic lighting, high detail, sharp focus, epic, movie still",
    "å‹•æ¼«é¢¨": "anime, manga style, vibrant colors, clean line art, studio ghibli style", 
    "è³½åšé¾å…‹": "cyberpunk, neon lights, futuristic city, high-tech, Blade Runner style",
    # è—è¡“æµæ´¾
    "å°è±¡æ´¾": "impressionism, soft light, visible brushstrokes, Monet style, oil painting", 
    "è¶…ç¾å¯¦ä¸»ç¾©": "surrealism, dreamlike, bizarre, Salvador Dali style, melting clocks",
    "æ™®æ™®è—è¡“": "pop art, bold colors, comic book style, Andy Warhol, Roy Lichtenstein", 
    "æ°´å¢¨ç•«": "ink wash painting, traditional chinese art, minimalist, zen, black ink on white paper",
    # æ•¸ä½èˆ‡éŠæˆ²é¢¨æ ¼
    "3D æ¨¡å‹": "3d model, octane render, unreal engine 5, hyperdetailed, 4k, volumetric lighting", 
    "åƒç´ è—è¡“": "pixel art, 16-bit, retro gaming style, sprite sheet, pixelated",
    "ä½é¢å»ºæ¨¡": "low poly, simple shapes, vibrant color palette, isometric, geometric", 
    "çŸ¢é‡åœ–": "vector art, flat design, clean lines, graphic illustration, adobe illustrator style",
    # å¹»æƒ³èˆ‡ç‰¹å®šé¢¨æ ¼
    "è’¸æ±½é¾å…‹": "steampunk, victorian era, brass gears, clockwork, copper pipes, intricate details", 
    "é»‘æš—å¥‡å¹»": "dark fantasy, gothic, grim, lovecraftian horror, moody lighting, dark atmosphere",
    "æ°´å½©ç•«": "watercolor painting, soft wash, blended colors, delicate, paper texture", 
    "å‰ªç´™è—è¡“": "paper cut-out, layered paper, papercraft, flat shapes, shadow box",
    "å¥‡å¹»è—è¡“": "fantasy art, epic, detailed, magical, lord of the rings style, dragons and wizards", 
    "æ¼«ç•«æ›¸": "comic book art, halftone dots, bold outlines, graphic novel style, superhero",
    "ç·šæ¢è—è¡“": "line art, monochrome, minimalist, clean lines, pen and ink", 
    "éœ“è™¹é¾å…‹": "neon punk, fluorescent, glowing, psychedelic, vibrant neon colors",
    "é»‘ç™½ç·šæ¢è—è¡“": "black and white line art, minimalist, clean vector, coloring book style",
    # æ–°å¢æ”å½±é¢¨æ ¼
    "äººåƒæ”å½±": "portrait photography, professional headshot, studio lighting, bokeh background",
    "è¡—é ­æ”å½±": "street photography, candid, urban, documentary style, natural lighting",
    "é¢¨æ™¯æ”å½±": "landscape photography, golden hour, wide angle, nature, scenic vista",
    "å¾®è·æ”å½±": "macro photography, extreme close-up, detailed textures, shallow depth of field",
    # æ–°å¢è—è¡“é¢¨æ ¼
    "æŠ½è±¡è¡¨ç¾ä¸»ç¾©": "abstract expressionism, Jackson Pollock style, paint splatters, emotional",
    "ç«‹é«”ä¸»ç¾©": "cubism, Pablo Picasso style, geometric shapes, fragmented perspective",
    "æ–°è—è¡“é‹å‹•": "art nouveau, ornate decorations, flowing lines, Alphonse Mucha style",
    "åŒ…è±ªæ–¯": "bauhaus style, geometric, functional design, minimalist, clean typography",
    "å¾©å¤æµ·å ±": "vintage poster, retro advertising, pin-up style, 1950s aesthetic",
}

def rerun_app():
    if hasattr(st, 'rerun'): st.rerun()
    elif hasattr(st, 'experimental_rerun'): st.experimental_rerun()
    else: st.stop()

st.set_page_config(page_title="AI åœ–åƒç”Ÿæˆå™¨ (å¤šæ¨¡å‹ç‰ˆ)", page_icon="ğŸ¨", layout="wide")

# å¤§å¹…æ“´å±•çš„APIä¾›æ‡‰å•†å’Œæ¨¡å‹é…ç½®
API_PROVIDERS = {
    "Pollinations.ai": {
        "name": "Pollinations.ai Studio", 
        "base_url_default": "https://image.pollinations.ai", 
        "icon": "ğŸŒ¸",
        "hardcoded_models": {
            # FLUX ç³»åˆ—
            "flux-1.1-pro": {"name": "Flux 1.1 Pro", "icon": "ğŸ†", "category": "FLUX"},
            "flux.1-kontext-pro": {"name": "Flux.1 Kontext Pro", "icon": "ğŸ§ ", "category": "FLUX"},
            "flux.1-kontext-max": {"name": "Flux.1 Kontext Max", "icon": "ğŸ‘‘", "category": "FLUX"},
            "flux-dev": {"name": "Flux Dev", "icon": "ğŸ› ï¸", "category": "FLUX"},
            "flux-schnell": {"name": "Flux Schnell", "icon": "âš¡", "category": "FLUX"},
            "flux-realism": {"name": "Flux Realism", "icon": "ğŸ“·", "category": "FLUX"},
            # Stable Diffusion ç³»åˆ—
            "stable-diffusion-3.5-large": {"name": "SD 3.5 Large", "icon": "ğŸ¯", "category": "Stable Diffusion"},
            "stable-diffusion-3.5-medium": {"name": "SD 3.5 Medium", "icon": "âš–ï¸", "category": "Stable Diffusion"},
            "stable-diffusion-xl": {"name": "SDXL 1.0", "icon": "ğŸ’", "category": "Stable Diffusion"},
            "stable-diffusion-xl-turbo": {"name": "SDXL Turbo", "icon": "ğŸš€", "category": "Stable Diffusion"},
            "stable-diffusion-2.1": {"name": "SD 2.1", "icon": "ğŸ”„", "category": "Stable Diffusion"},
            "stable-diffusion-1.5": {"name": "SD 1.5", "icon": "ğŸ”°", "category": "Stable Diffusion"},
            # å°ˆæ¥­æ¨¡å‹
            "midjourney": {"name": "Midjourney", "icon": "ğŸ­", "category": "Professional"},
            "dalle-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "OpenAI"},
            "playground-v2.5": {"name": "Playground v2.5", "icon": "ğŸª", "category": "Professional"},
            # ç‰¹åŒ–æ¨¡å‹
            "dreamshaper": {"name": "DreamShaper", "icon": "ğŸ’«", "category": "Community"},
            "realistic-vision": {"name": "Realistic Vision", "icon": "ğŸ‘ï¸", "category": "Community"},
            "deliberate": {"name": "Deliberate", "icon": "ğŸ¨", "category": "Community"},
            "anything-v5": {"name": "Anything v5", "icon": "ğŸŒŸ", "category": "Anime"},
            "waifu-diffusion": {"name": "Waifu Diffusion", "icon": "ğŸ‘©â€ğŸ¨", "category": "Anime"},
            "openjourney": {"name": "OpenJourney", "icon": "ğŸ—ºï¸", "category": "Community"},
            # é¢¨æ ¼ç‰¹åŒ–æ¨¡å‹
            "analog-diffusion": {"name": "Analog Film", "icon": "ğŸ“¸", "category": "Style"},
            "synthwave-diffusion": {"name": "Synthwave", "icon": "ğŸŒ†", "category": "Style"},
            "cyberpunk-anime": {"name": "Cyberpunk Anime", "icon": "ğŸ¤–", "category": "Style"},
            "pixel-art-xl": {"name": "Pixel Art XL", "icon": "ğŸ®", "category": "Style"},
        }
    },
    "NavyAI": {
        "name": "NavyAI", 
        "base_url_default": "https://api.navy/v1", 
        "icon": "âš“",
        "hardcoded_models": {
            "flux-pro": {"name": "Flux Pro", "icon": "ğŸ†", "category": "FLUX"},
            "flux-schnell": {"name": "Flux Schnell", "icon": "âš¡", "category": "FLUX"},
            "stable-diffusion-xl": {"name": "SDXL", "icon": "ğŸ’", "category": "Stable Diffusion"},
            "midjourney-v6": {"name": "Midjourney v6", "icon": "ğŸ­", "category": "Professional"},
        }
    },
    "OpenAI Compatible": {
        "name": "OpenAI å…¼å®¹ API", 
        "base_url_default": "https://api.openai.com/v1", 
        "icon": "ğŸ¤–",
        "hardcoded_models": {
            "dall-e-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "OpenAI"},
            "dall-e-2": {"name": "DALL-E 2", "icon": "ğŸ”„", "category": "OpenAI"},
        }
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "icon": "ğŸ¤—",
        "hardcoded_models": {
            "stable-diffusion-v1-5": {"name": "SD 1.5 (HF)", "icon": "ğŸ”°", "category": "Stable Diffusion"},
            "stable-diffusion-xl-base-1.0": {"name": "SDXL Base (HF)", "icon": "ğŸ’", "category": "Stable Diffusion"},
            "flux-1-dev": {"name": "Flux.1 Dev (HF)", "icon": "ğŸ› ï¸", "category": "FLUX"},
        }
    }
}

# åŸºç¤æ¨¡å‹é›†åˆ
BASE_MODELS = {
    "flux.1-schnell": {"name": "FLUX.1 Schnell", "icon": "âš¡", "priority": 1, "category": "FLUX"},
    "stable-diffusion-xl": {"name": "Stable Diffusion XL", "icon": "ğŸ’", "priority": 2, "category": "Stable Diffusion"},
    "stable-diffusion-1.5": {"name": "Stable Diffusion 1.5", "icon": "ğŸ”°", "priority": 3, "category": "Stable Diffusion"},
}

# --- æ ¸å¿ƒå‡½æ•¸ ---
def init_session_state():
    if 'api_profiles' not in st.session_state:
        try: 
            base_profiles = st.secrets.get("api_profiles", {})
        except StreamlitSecretNotFoundError: 
            base_profiles = {}
        
        default_profiles = {
            "é è¨­ Pollinations": {
                'provider': 'Pollinations.ai', 
                'api_key': '', 
                'base_url': 'https://image.pollinations.ai', 
                'validated': True, 
                'pollinations_auth_mode': 'å…è²»', 
                'pollinations_token': '', 
                'pollinations_referrer': ''
            }
        }
        
        st.session_state.api_profiles = base_profiles.copy() if base_profiles else default_profiles
        
    if 'active_profile_name' not in st.session_state or st.session_state.active_profile_name not in st.session_state.api_profiles:
        st.session_state.active_profile_name = list(st.session_state.api_profiles.keys())[0] if st.session_state.api_profiles else ""
    
    defaults = {
        'generation_history': [], 
        'favorite_images': [], 
        'discovered_models': {},
        'model_categories_expanded': {'FLUX': True, 'Stable Diffusion': True, 'Professional': False, 'Community': False, 'Anime': False, 'Style': False}
    }
    
    for key, value in defaults.items():
        if key not in st.session_state: 
            st.session_state[key] = value

def get_active_config(): 
    return st.session_state.api_profiles.get(st.session_state.active_profile_name, {})

def auto_discover_models(client, provider, base_url) -> Dict[str, Dict]:
    discovered = {}
    try:
        if provider == "Pollinations.ai":
            response = requests.get(f"{base_url}/models", timeout=10)
            if response.ok:
                models = response.json()
                for model_name in models: 
                    # æ™ºèƒ½åˆ†é¡
                    category = "Community"
                    if any(x in model_name.lower() for x in ['flux', 'kontext']):
                        category = "FLUX"
                    elif any(x in model_name.lower() for x in ['stable-diffusion', 'sd', 'sdxl']):
                        category = "Stable Diffusion"
                    elif any(x in model_name.lower() for x in ['anime', 'waifu', 'anything']):
                        category = "Anime"
                    elif any(x in model_name.lower() for x in ['midjourney', 'dalle', 'playground']):
                        category = "Professional"
                    
                    discovered[model_name] = {
                        "name": model_name.replace('-', ' ').replace('_', ' ').title(), 
                        "icon": "ğŸŒ¸",
                        "category": category
                    }
            else: 
                st.warning(f"ç„¡æ³•å¾ Pollinations ç²å–æ¨¡å‹åˆ—è¡¨: HTTP {response.status_code}")
                
        elif client:
            models = client.models.list().data
            for model in models:
                if any(keyword in model.id.lower() for keyword in ['flux', 'stable', 'dall', 'midjourney', 'sd']):
                    # æ™ºèƒ½åˆ†é¡å’Œåœ–æ¨™
                    category = "Community"
                    icon = "ğŸ¤–"
                    
                    if 'flux' in model.id.lower():
                        category = "FLUX"
                        icon = "âš¡"
                    elif any(x in model.id.lower() for x in ['stable', 'sd']):
                        category = "Stable Diffusion"
                        icon = "ğŸ’"
                    elif 'dall' in model.id.lower():
                        category = "OpenAI"
                        icon = "ğŸ¤–"
                    elif 'midjourney' in model.id.lower():
                        category = "Professional"
                        icon = "ğŸ­"
                    
                    discovered[model.id] = {
                        "name": model.id.replace('-', ' ').replace('_', ' ').title(), 
                        "icon": icon,
                        "category": category
                    }
    except Exception as e: 
        st.error(f"ç™¼ç¾æ¨¡å‹å¤±æ•—: {e}")
    return discovered

def merge_models() -> Dict[str, Dict]:
    provider = get_active_config().get('provider')
    discovered = st.session_state.get('discovered_models', {})
    
    if provider in API_PROVIDERS:
        hardcoded = API_PROVIDERS[provider].get('hardcoded_models', {})
        merged = {**hardcoded, **discovered}
    else:
        merged = {**BASE_MODELS, **discovered}
    
    return merged

def get_models_by_category(models: Dict[str, Dict]) -> Dict[str, Dict[str, Dict]]:
    """æŒ‰é¡åˆ¥çµ„ç¹”æ¨¡å‹"""
    categorized = {}
    for model_id, model_info in models.items():
        category = model_info.get('category', 'Other')
        if category not in categorized:
            categorized[category] = {}
        categorized[category][model_id] = model_info
    return categorized

def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    if provider == "Pollinations.ai": 
        return True, "Pollinations.ai ç„¡éœ€é©—è­‰"
    elif provider == "Hugging Face":
        if not api_key:
            return False, "Hugging Face éœ€è¦ API Token"
        try:
            headers = {"Authorization": f"Bearer {api_key}"}
            response = requests.get(f"{base_url}/models", headers=headers, timeout=10)
            if response.status_code == 200:
                return True, "Hugging Face API Token é©—è­‰æˆåŠŸ"
            else:
                return False, f"Hugging Face API é©—è­‰å¤±æ•—: {response.status_code}"
        except Exception as e:
            return False, f"Hugging Face API é©—è­‰å¤±æ•—: {e}"
    else:
        try: 
            OpenAI(api_key=api_key, base_url=base_url).models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
        except Exception as e: 
            return False, f"API é©—è­‰å¤±æ•—: {e}"

def generate_images_with_retry(client, **params) -> Tuple[bool, any]:
    provider = get_active_config().get('provider')
    n_images = params.get("n", 1)
    
    if provider == "Pollinations.ai":
        return generate_pollinations_images(params, n_images)
    elif provider == "Hugging Face":
        return generate_huggingface_images(params, n_images)
    else:
        return generate_openai_compatible_images(client, params, n_images)

def generate_pollinations_images(params, n_images):
    generated_images = []
    cfg = get_active_config()
    
    for i in range(n_images):
        try:
            current_params = params.copy()
            current_params["seed"] = random.randint(0, 1000000)
            prompt = current_params.get("prompt", "")
            
            if (neg_prompt := current_params.get("negative_prompt")): 
                prompt += f" --no {neg_prompt}"
                
            width, height = str(current_params.get("size", "1024x1024")).split('x')
            
            api_params = {
                k: v for k, v in {
                    "model": current_params.get("model"), 
                    "width": width, 
                    "height": height, 
                    "seed": current_params.get("seed"), 
                    "nologo": current_params.get("nologo"), 
                    "private": current_params.get("private"), 
                    "enhance": current_params.get("enhance"), 
                    "safe": current_params.get("safe")
                }.items() if v is not None
            }
            
            headers = {}
            auth_mode = cfg.get('pollinations_auth_mode', 'å…è²»')
            
            if auth_mode == 'ä»¤ç‰Œ' and cfg.get('pollinations_token'): 
                headers['Authorization'] = f"Bearer {cfg['pollinations_token']}"
            elif auth_mode == 'åŸŸå' and cfg.get('pollinations_referrer'): 
                headers['Referer'] = cfg['pollinations_referrer']
                
            url = f"{cfg['base_url']}/prompt/{quote(prompt)}?{urlencode(api_params)}"
            response = requests.get(url, headers=headers, timeout=120)
            
            if response.ok:
                b64_json = base64.b64encode(response.content).decode()
                image_obj = type('Image', (object,), {'b64_json': b64_json})
                generated_images.append(image_obj)
            else: 
                st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆå¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆæ™‚å‡ºéŒ¯: {e}")
            continue
            
    if generated_images:
        response_obj = type('Response', (object,), {'data': generated_images})
        return True, response_obj
    else: 
        return False, "æ‰€æœ‰åœ–ç‰‡ç”Ÿæˆå‡å¤±æ•—ã€‚"

def generate_huggingface_images(params, n_images):
    generated_images = []
    cfg = get_active_config()
    
    for i in range(n_images):
        try:
            headers = {"Authorization": f"Bearer {cfg['api_key']}"}
            model = params.get("model")
            prompt = params.get("prompt", "")
            
            # Hugging Face æ¨ç† API æ ¼å¼
            payload = {
                "inputs": prompt,
                "parameters": {
                    "negative_prompt": params.get("negative_prompt", ""),
                    "num_inference_steps": 20,
                    "guidance_scale": 7.5
                }
            }
            
            url = f"{cfg['base_url']}/models/{model}"
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            
            if response.ok:
                b64_json = base64.b64encode(response.content).decode()
                image_obj = type('Image', (object,), {'b64_json': b64_json})
                generated_images.append(image_obj)
            else:
                st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆå¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆæ™‚å‡ºéŒ¯: {e}")
            continue
            
    if generated_images:
        response_obj = type('Response', (object,), {'data': generated_images})
        return True, response_obj
    else:
        return False, "æ‰€æœ‰åœ–ç‰‡ç”Ÿæˆå‡å¤±æ•—ã€‚"

def generate_openai_compatible_images(client, params, n_images):
    try:
        sdk_params = {
            "model": params.get("model"), 
            "prompt": params.get("prompt"), 
            "size": str(params.get("size")), 
            "n": n_images, 
            "response_format": "b64_json"
        }
        
        # æ·»åŠ è² å‘æç¤ºè©æ”¯æŒï¼ˆå¦‚æœAPIæ”¯æŒï¼‰
        if params.get("negative_prompt"):
            sdk_params["negative_prompt"] = params.get("negative_prompt")
            
        sdk_params = {k: v for k, v in sdk_params.items() if v is not None and v != ""}
        return True, client.images.generate(**sdk_params)
    except Exception as e: 
        return False, str(e)

def add_to_history(prompt: str, negative_prompt: str, model: str, images: List[str], metadata: Dict):
    history = st.session_state.generation_history
    history.insert(0, {
        "id": str(uuid.uuid4()), 
        "timestamp": datetime.datetime.now(), 
        "prompt": prompt, 
        "negative_prompt": negative_prompt, 
        "model": model, 
        "images": images, 
        "metadata": metadata
    })
    st.session_state.generation_history = history[:MAX_HISTORY_ITEMS]

def display_image_with_actions(b64_json: str, image_id: str, history_item: Dict):
    try:
        img_data = base64.b64decode(b64_json)
        st.image(Image.open(BytesIO(img_data)), use_container_width=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1: 
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰", 
                img_data, 
                f"ai_generated_{image_id}.png", 
                "image/png", 
                key=f"dl_{image_id}", 
                use_container_width=True
            )
            
        with col2:
            is_fav = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button(
                "â­" if is_fav else "â˜†", 
                key=f"fav_{image_id}", 
                use_container_width=True, 
                help="æ”¶è—/å–æ¶ˆæ”¶è—"
            ):
                if is_fav: 
                    st.session_state.favorite_images = [
                        f for f in st.session_state.favorite_images 
                        if f['id'] != image_id
                    ]
                else: 
                    st.session_state.favorite_images.append({
                        "id": image_id, 
                        "image_b64": b64_json, 
                        "timestamp": datetime.datetime.now(), 
                        "history_item": history_item
                    })
                rerun_app()
                
        with col3:
            if st.button(
                "ğŸ¨ è®Šé«”", 
                key=f"vary_{image_id}", 
                use_container_width=True, 
                help="ä½¿ç”¨æ­¤æç¤ºç”Ÿæˆè®Šé«”"
            ):
                st.session_state.update({
                    'vary_prompt': history_item['prompt'], 
                    'vary_negative_prompt': history_item.get('negative_prompt', ''), 
                    'vary_model': history_item['model']
                })
                rerun_app()
                
    except Exception as e: 
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {e}")

def init_api_client():
    cfg = get_active_config()
    if cfg and cfg.get('api_key') and cfg.get('provider') not in ["Pollinations.ai", "Hugging Face"]:
        try: 
            return OpenAI(api_key=cfg['api_key'], base_url=cfg['base_url'])
        except Exception: 
            return None
    return None

def editor_provider_changed():
    provider = st.session_state.editor_provider_selectbox
    st.session_state.editor_base_url = API_PROVIDERS[provider]['base_url_default']
    st.session_state.editor_api_key = ""

def load_profile_to_editor_state(profile_name):
    config = st.session_state.api_profiles.get(profile_name, {})
    provider = config.get('provider', 'Pollinations.ai')
    
    st.session_state.editor_provider_selectbox = provider
    st.session_state.editor_base_url = config.get(
        'base_url', 
        API_PROVIDERS.get(provider, {}).get('base_url_default', '')
    )
    st.session_state.editor_api_key = config.get('api_key', '')
    st.session_state.editor_auth_mode = config.get('pollinations_auth_mode', 'å…è²»')
    st.session_state.editor_referrer = config.get('pollinations_referrer', '')
    st.session_state.editor_token = config.get('pollinations_token', '')
    st.session_state.profile_being_edited = profile_name

def show_api_settings():
    st.subheader("âš™ï¸ API å­˜æª”ç®¡ç†")
    
    profile_names = list(st.session_state.api_profiles.keys())
    if not profile_names: 
        st.warning("æ²’æœ‰å¯ç”¨çš„ API å­˜æª”ã€‚è«‹æ–°å¢ä¸€å€‹ã€‚")
        
    active_profile_name = st.selectbox(
        "æ´»å‹•å­˜æª”", 
        profile_names, 
        index=profile_names.index(st.session_state.get('active_profile_name')) 
        if st.session_state.get('active_profile_name') in profile_names else 0
    )
    
    if (st.session_state.get('active_profile_name') != active_profile_name or 
        'profile_being_edited' not in st.session_state or 
        st.session_state.profile_being_edited != active_profile_name):
        
        st.session_state.active_profile_name = active_profile_name
        load_profile_to_editor_state(active_profile_name)
        st.session_state.discovered_models = {}
        rerun_app()

    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("â• æ–°å¢å­˜æª”", use_container_width=True):
            new_name = "æ–°å­˜æª”"
            count = 1
            while new_name in st.session_state.api_profiles: 
                new_name = f"æ–°å­˜æª”_{count}"
                count += 1
                
            st.session_state.api_profiles[new_name] = {
                'provider': 'Pollinations.ai', 
                'validated': False, 
                'base_url': API_PROVIDERS['Pollinations.ai']['base_url_default']
            }
            st.session_state.active_profile_name = new_name
            rerun_app()
            
    with col2:
        if st.button(
            "ğŸ—‘ï¸ åˆªé™¤ç•¶å‰å­˜æª”", 
            use_container_width=True, 
            disabled=len(profile_names) <= 1 or not active_profile_name
        ):
            if active_profile_name:
                del st.session_state.api_profiles[active_profile_name]
                st.session_state.active_profile_name = list(st.session_state.api_profiles.keys())[0]
                rerun_app()

    if active_profile_name:
        with st.expander("ğŸ“ ç·¨è¼¯ç•¶å‰æ´»å‹•å­˜æª”", expanded=True):
            st.text_input("å­˜æª”åç¨±", value=active_profile_name, key="editor_profile_name")
            
            st.selectbox(
                "API æä¾›å•†", 
                list(API_PROVIDERS.keys()), 
                key='editor_provider_selectbox', 
                on_change=editor_provider_changed
            )
            
            st.text_input("API ç«¯é» URL", key='editor_base_url')
            
            provider = st.session_state.editor_provider_selectbox
            
            if provider == "Pollinations.ai":
                st.radio(
                    "èªè­‰æ¨¡å¼", 
                    ["å…è²»", "åŸŸå", "ä»¤ç‰Œ"], 
                    key='editor_auth_mode', 
                    horizontal=True
                )
                st.text_input(
                    "æ‡‰ç”¨åŸŸå (Referrer)", 
                    key='editor_referrer', 
                    disabled=(st.session_state.editor_auth_mode != 'åŸŸå')
                )
                st.text_input(
                    "API ä»¤ç‰Œ (Token)", 
                    key='editor_token', 
                    type="password", 
                    disabled=(st.session_state.editor_auth_mode != 'ä»¤ç‰Œ')
                )
            else: 
                st.text_input("API å¯†é‘°", key='editor_api_key', type="password")

            if st.button("ğŸ’¾ ä¿å­˜/æ›´æ–°å­˜æª”", type="primary"):
                provider = st.session_state.editor_provider_selectbox
                new_config = {
                    'provider': provider, 
                    'base_url': st.session_state.editor_base_url
                }
                
                if provider == "Pollinations.ai":
                    new_config.update({
                        'api_key': '', 
                        'pollinations_auth_mode': st.session_state.editor_auth_mode, 
                        'pollinations_referrer': st.session_state.editor_referrer, 
                        'pollinations_token': st.session_state.editor_token
                    })
                else: 
                    new_config.update({
                        'api_key': st.session_state.editor_api_key, 
                        'pollinations_auth_mode': 'å…è²»', 
                        'pollinations_referrer': '', 
                        'pollinations_token': ''
                    })
                    
                is_valid, msg = validate_api_key(
                    new_config['api_key'], 
                    new_config['base_url'], 
                    new_config['provider']
                )
                new_config['validated'] = is_valid
                
                new_name = st.session_state.editor_profile_name
                if new_name != active_profile_name: 
                    del st.session_state.api_profiles[active_profile_name]
                    
                st.session_state.api_profiles[new_name] = new_config
                st.session_state.active_profile_name = new_name
                
                st.success(f"å­˜æª” '{new_name}' å·²ä¿å­˜ã€‚ç‹€æ…‹: {msg}")
                time.sleep(1)
                rerun_app()

def show_model_selector(all_models):
    """é¡¯ç¤ºåˆ†é¡çš„æ¨¡å‹é¸æ“‡å™¨"""
    categorized_models = get_models_by_category(all_models)
    
    # ç²å–é»˜èªå€¼
    prompt_default = st.session_state.pop('vary_prompt', '')
    neg_prompt_default = st.session_state.pop('vary_negative_prompt', '')
    model_default_key = st.session_state.pop('vary_model', list(all_models.keys())[0])
    
    st.subheader("ğŸ¤– æ¨¡å‹é¸æ“‡")
    
    # é¡¯ç¤ºæ¨¡å‹çµ±è¨ˆ
    total_models = len(all_models)
    categories_count = len(categorized_models)
    st.caption(f"å¯ç”¨æ¨¡å‹: {total_models} å€‹ï¼Œåˆ†ç‚º {categories_count} å€‹é¡åˆ¥")
    
    selected_model = None
    
    # æŒ‰é¡åˆ¥é¡¯ç¤ºæ¨¡å‹
    for category, models in categorized_models.items():
        # å±•é–‹/æ”¶åˆç‹€æ…‹
        expanded_key = f"category_{category}_expanded"
        if expanded_key not in st.session_state:
            st.session_state[expanded_key] = category in ['FLUX', 'Stable Diffusion']
            
        with st.expander(f"ğŸ“ {category} ({len(models)} å€‹æ¨¡å‹)", expanded=st.session_state[expanded_key]):
            # å‰µå»ºç¶²æ ¼å¸ƒå±€
            cols = st.columns(3)
            for i, (model_id, model_info) in enumerate(models.items()):
                col = cols[i % 3]
                with col:
                    model_name = f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', model_id)}"
                    if st.button(
                        model_name, 
                        key=f"select_model_{model_id}",
                        use_container_width=True,
                        type="primary" if model_id == model_default_key else "secondary"
                    ):
                        selected_model = model_id
                        st.session_state.selected_model = model_id
                        rerun_app()
    
    # è¿”å›é¸ä¸­çš„æ¨¡å‹
    if selected_model:
        return selected_model
    elif 'selected_model' in st.session_state and st.session_state.selected_model in all_models:
        return st.session_state.selected_model
    else:
        return model_default_key if model_default_key in all_models else list(all_models.keys())[0]

# åˆå§‹åŒ–
init_session_state()
client = init_api_client()
cfg = get_active_config()
api_configured = cfg and cfg.get('validated', False)

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    show_api_settings()
    st.markdown("---")
    
    if api_configured:
        st.success(f"ğŸŸ¢ æ´»å‹•å­˜æª”: '{st.session_state.active_profile_name}'")
        
        # é¡¯ç¤ºç•¶å‰APIä¾›æ‡‰å•†ä¿¡æ¯
        provider_info = API_PROVIDERS.get(cfg['provider'], {})
        st.info(f"{provider_info.get('icon', 'ğŸ¤–')} {provider_info.get('name', cfg['provider'])}")
        
        can_discover = (client is not None) or (cfg.get('provider') in ["Pollinations.ai", "Hugging Face"])
        
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True, disabled=not can_discover):
            with st.spinner("ğŸ” æ­£åœ¨ç™¼ç¾æ¨¡å‹..."):
                discovered = auto_discover_models(client, cfg['provider'], cfg['base_url'])
                st.session_state.discovered_models = discovered
                if discovered:
                    st.success(f"ç™¼ç¾ {len(discovered)} å€‹æ¨¡å‹ï¼")
                else:
                    st.warning("æœªç™¼ç¾ä»»ä½•æ¨¡å‹ã€‚")
                time.sleep(1)
                rerun_app()
                
    elif st.session_state.api_profiles: 
        st.error(f"ğŸ”´ '{st.session_state.active_profile_name}' æœªé©—è­‰")
        
    st.markdown("---")
    st.info(f"âš¡ **å¢å¼·ç‰ˆå„ªåŒ–**\n- æ­·å²: {MAX_HISTORY_ITEMS}\n- æ”¶è—: {MAX_FAVORITE_ITEMS}\n- æ‰¹é‡: {MAX_BATCH_SIZE}")

# --- ä¸»æ¨™é¡Œ ---
st.title("ğŸ¨ AI åœ–åƒç”Ÿæˆå™¨ (å¤šæ¨¡å‹å¢å¼·ç‰ˆ)")
st.caption("æ”¯æ´ FLUXã€Stable Diffusionã€DALL-E åŠæ›´å¤šæ¨¡å‹")

# --- ä¸»ä»‹é¢ ---
tab1, tab2, tab3 = st.tabs([
    "ğŸš€ ç”Ÿæˆåœ–åƒ", 
    f"ğŸ“š æ­·å² ({len(st.session_state.generation_history)})", 
    f"â­ æ”¶è— ({len(st.session_state.favorite_images)})"
])

with tab1:
    if not api_configured: 
        st.warning("âš ï¸ è«‹åœ¨å´é‚Šæ¬„é¸æ“‡ä¸€å€‹å·²é©—è­‰çš„å­˜æª”ï¼Œæˆ–æ–°å¢ä¸€å€‹ã€‚")
    else:
        all_models = merge_models()
        if not all_models: 
            st.warning("âš ï¸ æœªç™¼ç¾ä»»ä½•æ¨¡å‹ã€‚è«‹é»æ“Šå´é‚Šæ¬„çš„ã€Œç™¼ç¾æ¨¡å‹ã€ã€‚")
        else:
            # æ¨¡å‹é¸æ“‡
            selected_model = show_model_selector(all_models)
            
            # é¡¯ç¤ºç•¶å‰é¸ä¸­çš„æ¨¡å‹
            if selected_model:
                model_info = all_models[selected_model]
                st.success(f"å·²é¸æ“‡æ¨¡å‹: {model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', selected_model)}")
            
            st.markdown("---")
            
            # ç”Ÿæˆåƒæ•¸
            col1, col2 = st.columns([2, 1])
            
            with col1:
                prompt_default = st.session_state.get('vary_prompt', '')
                neg_prompt_default = st.session_state.get('vary_negative_prompt', '')
                
                selected_style = st.selectbox("ğŸ¨ é¢¨æ ¼é è¨­:", list(STYLE_PRESETS.keys()))
                
                prompt_val = st.text_area(
                    "âœï¸ æç¤ºè©:", 
                    value=prompt_default, 
                    height=100, 
                    placeholder="ä¸€éš»è²“åœ¨æ—¥è½ä¸‹é£›ç¿”ï¼Œé›»å½±æ„Ÿï¼Œé«˜å“è³ª"
                )
                
                negative_prompt_val = st.text_area(
                    "ğŸš« è² å‘æç¤ºè©:", 
                    value=neg_prompt_default, 
                    height=50, 
                    placeholder="æ¨¡ç³Š, ç³Ÿç³•çš„è§£å‰–çµæ§‹, æ–‡å­—, æ°´å°"
                )
                
            with col2:
                n_images = st.slider("ç”Ÿæˆæ•¸é‡", 1, MAX_BATCH_SIZE, 1)
                
                size_preset = st.selectbox(
                    "åœ–åƒå°ºå¯¸", 
                    options=list(IMAGE_SIZES.keys()), 
                    format_func=lambda x: IMAGE_SIZES[x]
                )
                
                final_size_str = size_preset
                if size_preset == "è‡ªå®šç¾©...":
                    width = st.slider("å¯¬åº¦", 256, 2048, 1024, 64)
                    height = st.slider("é«˜åº¦", 256, 2048, 1024, 64)
                    final_size_str = f"{width}x{height}"
            
            # API ç‰¹å®šé¸é …
            enhance, private, nologo, safe = False, False, False, False
            
            if cfg.get('provider') == "Pollinations.ai":
                with st.expander("ğŸŒ¸ Pollinations.ai é€²éšé¸é …"):
                    col1, col2 = st.columns(2)
                    with col1:
                        enhance = st.checkbox("å¢å¼·æç¤ºè©", True)
                        private = st.checkbox("ç§å¯†æ¨¡å¼", True)
                    with col2:
                        nologo = st.checkbox("ç§»é™¤æ¨™èªŒ", True)
                        safe = st.checkbox("å®‰å…¨æ¨¡å¼", False)
            
            elif cfg.get('provider') == "Hugging Face":
                with st.expander("ğŸ¤— Hugging Face é€²éšé¸é …"):
                    col1, col2 = st.columns(2)
                    with col1:
                        inference_steps = st.slider("æ¨ç†æ­¥é©Ÿ", 10, 50, 20)
                        guidance_scale = st.slider("å¼•å°å¼·åº¦", 1.0, 20.0, 7.5, 0.5)
                    with col2:
                        scheduler = st.selectbox("èª¿åº¦å™¨", ["DPMSolverMultistep", "EulerDiscrete", "DDIM"])
            
            # ç”ŸæˆæŒ‰éˆ•
            if st.button(
                "ğŸš€ ç”Ÿæˆåœ–åƒ", 
                type="primary", 
                use_container_width=True, 
                disabled=not prompt_val.strip() or not selected_model
            ):
                final_prompt = (
                    f"{prompt_val}, {STYLE_PRESETS[selected_style]}" 
                    if selected_style != "ç„¡" and STYLE_PRESETS[selected_style] 
                    else prompt_val
                )
                
                with st.spinner(f"ğŸ¨ æ­£åœ¨ä½¿ç”¨ {all_models[selected_model]['name']} ç”Ÿæˆ {n_images} å¼µåœ–åƒ..."):
                    params = {
                        "model": selected_model, 
                        "prompt": final_prompt, 
                        "negative_prompt": negative_prompt_val, 
                        "size": final_size_str, 
                        "n": n_images, 
                        "enhance": enhance, 
                        "private": private, 
                        "nologo": nologo, 
                        "safe": safe
                    }
                    
                    success, result = generate_images_with_retry(client, **params)
                    
                    if success and result.data:
                        img_b64s = [img.b64_json for img in result.data]
                        add_to_history(
                            prompt_val, 
                            negative_prompt_val, 
                            selected_model, 
                            img_b64s, 
                            {
                                "size": final_size_str, 
                                "provider": cfg['provider'], 
                                "style": selected_style, 
                                "n": n_images,
                                "model_name": all_models[selected_model]['name']
                            }
                        )
                        
                        st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(img_b64s)} å¼µåœ–åƒï¼")
                        
                        # é¡¯ç¤ºç”Ÿæˆçš„åœ–åƒ
                        cols = st.columns(min(len(img_b64s), 2))
                        for i, b64_json in enumerate(img_b64s):
                            with cols[i % 2]: 
                                display_image_with_actions(
                                    b64_json, 
                                    f"{st.session_state.generation_history[0]['id']}_{i}", 
                                    st.session_state.generation_history[0]
                                )
                        
                        gc.collect()
                    else: 
                        st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")

with tab2:
    if not st.session_state.generation_history: 
        st.info("ğŸ“­ å°šç„¡ç”Ÿæˆæ­·å²ã€‚")
    else:
        for item in st.session_state.generation_history:
            timestamp_str = item['timestamp'].strftime('%m-%d %H:%M')
            model_name = all_models.get(item['model'], {}).get('name', item['model']) if 'all_models' in locals() else item['model']
            
            with st.expander(f"ğŸ¨ {item['prompt'][:50]}... | {model_name} | {timestamp_str}"):
                st.markdown(f"**æç¤ºè©**: {item['prompt']}")
                st.markdown(f"**æ¨¡å‹**: {model_name}")
                
                if item.get('negative_prompt'): 
                    st.markdown(f"**è² å‘æç¤ºè©**: {item['negative_prompt']}")
                    
                if item.get('metadata', {}).get('style'):
                    st.markdown(f"**é¢¨æ ¼**: {item['metadata']['style']}")
                    
                cols = st.columns(min(len(item['images']), 2))
                for i, b64_json in enumerate(item['images']):
                    with cols[i % 2]: 
                        display_image_with_actions(b64_json, f"hist_{item['id']}_{i}", item)

with tab3:
    if not st.session_state.favorite_images: 
        st.info("â­ å°šç„¡æ”¶è—çš„åœ–åƒã€‚")
    else:
        # æ”¶è—ç®¡ç†
        col1, col2 = st.columns([3, 1])
        with col1:
            st.subheader(f"â­ æˆ‘çš„æ”¶è— ({len(st.session_state.favorite_images)} å¼µ)")
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ”¶è—", use_container_width=True):
                st.session_state.favorite_images = []
                rerun_app()
        
        # é¡¯ç¤ºæ”¶è—çš„åœ–åƒ
        cols = st.columns(3)
        for i, fav in enumerate(sorted(st.session_state.favorite_images, key=lambda x: x['timestamp'], reverse=True)):
            with cols[i % 3]: 
                display_image_with_actions(
                    fav['image_b64'], 
                    fav['id'], 
                    fav.get('history_item', {})
                )

# --- é è…³ ---
st.markdown("---")
st.markdown(
    """<div style="text-align: center; color: #888; margin-top: 2rem;">
    <small>ğŸ¨ å¤šæ¨¡å‹å¢å¼·ç‰ˆ | æ”¯æ´ FLUXã€Stable Diffusionã€DALL-E ç­‰ | éƒ¨ç½²åœ¨é›²ç«¯å¹³å° ğŸ¨</small>
    </div>""", 
    unsafe_allow_html=True
)
