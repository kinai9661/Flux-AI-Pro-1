import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Tuple, Optional
import time
import random
import uuid
import os
from urllib.parse import urlencode, quote
import gc
from streamlit.errors import StreamlitAPIException

# æ‡‰ç”¨é…ç½®
APP_TITLE = "ğŸ¨ AI åœ–åƒç”Ÿæˆå™¨ (æ”¹é€²é¸æ“‡å™¨ç‰ˆ)"
VERSION = "v1.6.0"

# é™åˆ¶é…ç½®
MAX_HISTORY_ITEMS = 20
MAX_FAVORITE_ITEMS = 40
MAX_BATCH_SIZE = 4
REQUEST_TIMEOUT = 120

# åœ–åƒå°ºå¯¸é è¨­
IMAGE_SIZES = {
    "è‡ªå®šç¾©...": "Custom",
    "512x512": "SD æ¨™æº– (1:1)", 
    "768x768": "SD XL æ¨™æº– (1:1)",
    "1024x1024": "æ­£æ–¹å½¢ (1:1)", 
    "1080x1080": "IG è²¼æ–‡ (1:1)",
    "512x768": "SD ç¸±å‘ (2:3)",
    "768x1024": "SDXL ç¸±å‘ (3:4)",
    "1080x1350": "IG ç¸±å‘ (4:5)", 
    "1080x1920": "IG Story (9:16)",
    "768x512": "SD æ©«å‘ (3:2)",
    "1024x768": "SDXL æ©«å‘ (4:3)",
    "1200x630": "FB æ©«å‘ (1.91:1)",
    "1536x640": "è¶…å¯¬æ©«å¹… (2.4:1)",
}

# é¢¨æ ¼é è¨­
STYLE_PRESETS = {
    "ç„¡": "",
    "é›»å½±æ„Ÿ": "cinematic, dramatic lighting, high detail, sharp focus, epic scene",
    "å‹•æ¼«é¢¨": "anime, manga style, vibrant colors, clean line art, studio ghibli", 
    "è³½åšé¾å…‹": "cyberpunk, neon lights, futuristic city, high-tech, Blade Runner",
    "äººåƒæ”å½±": "portrait photography, professional headshot, studio lighting, bokeh",
    "è¡—é ­æ”å½±": "street photography, candid moment, urban setting, natural lighting",
    "é¢¨æ™¯æ”å½±": "landscape photography, golden hour lighting, wide angle view, HDR",
    "å°è±¡æ´¾": "impressionism, soft brushstrokes, natural light, Monet style",
    "è¶…ç¾å¯¦ä¸»ç¾©": "surrealism, dreamlike imagery, Salvador Dali style",
    "æ™®æ™®è—è¡“": "pop art, bold colors, comic book style, Andy Warhol",
    "æ°´å¢¨ç•«": "traditional Chinese ink painting, minimalist zen aesthetic",
    "æ°´å½©ç•«": "watercolor painting, soft transparent washes, delicate colors",
    "3D æ¸²æŸ“": "3D render, octane rendering, photorealistic, volumetric lighting",
    "åƒç´ è—è¡“": "pixel art, 8-bit style, retro gaming aesthetic",
    "è’¸æ±½é¾å…‹": "steampunk aesthetic, Victorian era meets technology",
    "å¥‡å¹»è—è¡“": "fantasy art, magical creatures, epic landscapes",
    "ç§‘å¹»è—è¡“": "science fiction art, futuristic technology, space scenes",
    "ç¾å¼æ¼«ç•«": "American comic book style, bold outlines, dynamic poses",
    "æ—¥å¼æ¼«ç•«": "manga style, detailed line art, expressive characters",
    "é»‘ç™½æ”å½±": "black and white photography, high contrast, dramatic shadows",
    "çŸ¢é‡åœ–": "vector illustration, clean geometric lines, flat design",
    "æ²¹ç•«": "oil painting, thick impasto, rich textures, renaissance style",
    "ç´ æ": "pencil sketch, graphite drawing, crosshatching, detailed line work",
    "åŒ…è±ªæ–¯": "Bauhaus design, geometric minimalism, functional aesthetics",
    "è£é£¾è—è¡“": "art deco style, geometric patterns, luxury aesthetics",
}

# è² å‘æç¤ºè©é è¨­
NEGATIVE_PROMPTS = {
    "åŸºæœ¬": "blurry, low quality, distorted, deformed, ugly, bad anatomy",
    "æ”å½±": "blurry, low resolution, overexposed, underexposed, noise",
    "äººåƒ": "bad anatomy, deformed face, extra limbs, missing fingers",
    "å‹•æ¼«": "realistic, photographic, 3d render, western cartoon",
    "è—è¡“": "photographic, realistic, low quality, commercial",
}

def rerun_app():
    try:
        if hasattr(st, 'rerun'):
            st.rerun()
        elif hasattr(st, 'experimental_rerun'):
            st.experimental_rerun()
        else:
            st.stop()
    except Exception:
        st.stop()

st.set_page_config(
    page_title=APP_TITLE,
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# APIä¾›æ‡‰å•†é…ç½®
API_PROVIDERS = {
    "Pollinations.ai": {
        "name": "Pollinations.ai Studio",
        "base_url_default": "https://image.pollinations.ai",
        "icon": "ğŸŒ¸",
        "hardcoded_models": {
            # FLUX ç³»åˆ—
            "flux-1.1-pro": {"name": "Flux 1.1 Pro", "icon": "ğŸ†", "category": "FLUX", "quality": "æœ€é«˜", "speed": "æ…¢", "description": "æœ€æ–°æ——è‰¦ç´šFLUXæ¨¡å‹ï¼Œè³ªé‡æœ€ä½³"},
            "flux.1-kontext-pro": {"name": "Flux.1 Kontext Pro", "icon": "ğŸ§ ", "category": "FLUX", "quality": "é«˜", "speed": "ä¸­", "description": "ä¸Šä¸‹æ–‡ç†è§£å¢å¼·ç‰ˆ"},
            "flux.1-kontext-max": {"name": "Flux.1 Kontext Max", "icon": "ğŸ‘‘", "category": "FLUX", "quality": "æœ€é«˜", "speed": "æ…¢", "description": "æœ€å¼·ä¸Šä¸‹æ–‡ç†è§£"},
            "flux-dev": {"name": "Flux Dev", "icon": "ğŸ› ï¸", "category": "FLUX", "quality": "é«˜", "speed": "ä¸­", "description": "é–‹ç™¼è€…ç‰ˆæœ¬ï¼Œå¹³è¡¡æ€§èƒ½"},
            "flux-schnell": {"name": "Flux Schnell", "icon": "âš¡", "category": "FLUX", "quality": "ä¸­", "speed": "å¿«", "description": "å¿«é€Ÿç”Ÿæˆç‰ˆæœ¬"},
            "flux-realism": {"name": "Flux Realism", "icon": "ğŸ“·", "category": "FLUX", "quality": "é«˜", "speed": "ä¸­", "description": "å¯«å¯¦é¢¨æ ¼å°ˆç”¨"},
            
            # Stable Diffusion ç³»åˆ—
            "stable-diffusion-3.5-large": {"name": "SD 3.5 Large", "icon": "ğŸ¯", "category": "Stable Diffusion", "quality": "æœ€é«˜", "speed": "æ…¢", "description": "æœ€æ–°å¤§å‹SDæ¨¡å‹"},
            "stable-diffusion-3.5-medium": {"name": "SD 3.5 Medium", "icon": "âš–ï¸", "category": "Stable Diffusion", "quality": "é«˜", "speed": "ä¸­", "description": "å¹³è¡¡æ€§èƒ½ç‰ˆæœ¬"},
            "stable-diffusion-xl": {"name": "SDXL 1.0", "icon": "ğŸ’", "category": "Stable Diffusion", "quality": "é«˜", "speed": "ä¸­", "description": "é«˜åˆ†è¾¨ç‡æ¨™æº–ç‰ˆ"},
            "stable-diffusion-xl-turbo": {"name": "SDXL Turbo", "icon": "ğŸš€", "category": "Stable Diffusion", "quality": "ä¸­", "speed": "å¿«", "description": "å¿«é€Ÿç”Ÿæˆç‰ˆ"},
            "stable-diffusion-2.1": {"name": "SD 2.1", "icon": "ğŸ”„", "category": "Stable Diffusion", "quality": "ä¸­", "speed": "å¿«", "description": "ç©©å®šç‰ˆæœ¬"},
            "stable-diffusion-1.5": {"name": "SD 1.5", "icon": "ğŸ”°", "category": "Stable Diffusion", "quality": "ä¸­", "speed": "å¿«", "description": "ç¶“å…¸ç‰ˆæœ¬"},
            
            # å°ˆæ¥­æ¨¡å‹
            "midjourney": {"name": "Midjourney", "icon": "ğŸ­", "category": "Professional", "quality": "æœ€é«˜", "speed": "ä¸­", "description": "è—è¡“å‰µä½œå°ˆå®¶"},
            "dalle-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "Professional", "quality": "æœ€é«˜", "speed": "ä¸­", "description": "OpenAIæœ€æ–°æ¨¡å‹"},
            "playground-v2.5": {"name": "Playground v2.5", "icon": "ğŸª", "category": "Professional", "quality": "é«˜", "speed": "ä¸­", "description": "å•†æ¥­ç´šæ¨¡å‹"},
            
            # ç¤¾å€æ¨¡å‹
            "dreamshaper": {"name": "DreamShaper", "icon": "ğŸ’«", "category": "Community", "quality": "é«˜", "speed": "ä¸­", "description": "å¤¢å¢ƒé¢¨æ ¼ç”Ÿæˆ"},
            "realistic-vision": {"name": "Realistic Vision", "icon": "ğŸ‘ï¸", "category": "Community", "quality": "é«˜", "speed": "ä¸­", "description": "è¶…ç¾å¯¦ä¸»ç¾©"},
            "deliberate": {"name": "Deliberate", "icon": "ğŸ¨", "category": "Community", "quality": "é«˜", "speed": "ä¸­", "description": "ç²¾ç´°æ§åˆ¶"},
            "anything-v5": {"name": "Anything v5", "icon": "ğŸŒŸ", "category": "Anime", "quality": "é«˜", "speed": "ä¸­", "description": "è¬èƒ½å‹•æ¼«æ¨¡å‹"},
            "waifu-diffusion": {"name": "Waifu Diffusion", "icon": "ğŸ‘©â€ğŸ¨", "category": "Anime", "quality": "é«˜", "speed": "ä¸­", "description": "å‹•æ¼«è§’è‰²å°ˆç”¨"},
            "openjourney": {"name": "OpenJourney", "icon": "ğŸ—ºï¸", "category": "Community", "quality": "ä¸­", "speed": "å¿«", "description": "é–‹æ”¾å¼å‰µä½œ"},
            
            # é¢¨æ ¼æ¨¡å‹
            "analog-diffusion": {"name": "Analog Film", "icon": "ğŸ“¸", "category": "Style", "quality": "ä¸­", "speed": "å¿«", "description": "è† ç‰‡æ”å½±é¢¨æ ¼"},
            "synthwave-diffusion": {"name": "Synthwave", "icon": "ğŸŒ†", "category": "Style", "quality": "ä¸­", "speed": "å¿«", "description": "åˆæˆæ³¢é¢¨æ ¼"},
            "cyberpunk-anime": {"name": "Cyberpunk Anime", "icon": "ğŸ¤–", "category": "Style", "quality": "ä¸­", "speed": "å¿«", "description": "è³½åšæœ‹å…‹å‹•æ¼«"},
            "pixel-art-xl": {"name": "Pixel Art XL", "icon": "ğŸ®", "category": "Style", "quality": "ä¸­", "speed": "å¿«", "description": "åƒç´ è—è¡“"},
        }
    },
    "NavyAI": {
        "name": "NavyAI",
        "base_url_default": "https://api.navy/v1",
        "icon": "âš“",
        "hardcoded_models": {
            "flux-pro": {"name": "Flux Pro", "icon": "ğŸ†", "category": "FLUX", "quality": "æœ€é«˜", "speed": "ä¸­", "description": "å•†æ¥­ç´šFLUX"},
            "flux-schnell": {"name": "Flux Schnell", "icon": "âš¡", "category": "FLUX", "quality": "ä¸­", "speed": "å¿«", "description": "å¿«é€Ÿç”Ÿæˆ"},
            "stable-diffusion-xl": {"name": "SDXL", "icon": "ğŸ’", "category": "Stable Diffusion", "quality": "é«˜", "speed": "ä¸­", "description": "é«˜åˆ†è¾¨ç‡"},
            "midjourney-v6": {"name": "Midjourney v6", "icon": "ğŸ­", "category": "Professional", "quality": "æœ€é«˜", "speed": "ä¸­", "description": "æœ€æ–°Midjourney"},
        }
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "icon": "ğŸ¤—",
        "hardcoded_models": {
            "stable-diffusion-v1-5": {"name": "SD 1.5 (HF)", "icon": "ğŸ”°", "category": "Stable Diffusion", "quality": "ä¸­", "speed": "å¿«", "description": "é–‹æºç¶“å…¸"},
            "stable-diffusion-xl-base-1.0": {"name": "SDXL Base (HF)", "icon": "ğŸ’", "category": "Stable Diffusion", "quality": "é«˜", "speed": "ä¸­", "description": "é–‹æºSDXL"},
            "flux-1-dev": {"name": "Flux.1 Dev (HF)", "icon": "ğŸ› ï¸", "category": "FLUX", "quality": "é«˜", "speed": "ä¸­", "description": "é–‹æºFLUX"},
        }
    },
    "OpenAI Compatible": {
        "name": "OpenAI å…¼å®¹ API",
        "base_url_default": "https://api.openai.com/v1",
        "icon": "ğŸ¤–",
        "hardcoded_models": {
            "dall-e-3": {"name": "DALL-E 3", "icon": "ğŸ¤–", "category": "OpenAI", "quality": "æœ€é«˜", "speed": "ä¸­", "description": "æœ€æ–°DALL-E"},
            "dall-e-2": {"name": "DALL-E 2", "icon": "ğŸ”„", "category": "OpenAI", "quality": "é«˜", "speed": "å¿«", "description": "ç¶“å…¸DALL-E"},
        }
    }
}

# æ¨¡å‹é¸æ“‡å™¨æ¨£å¼
MODEL_SELECTOR_STYLES = {
    "dropdown": "ä¸‹æ‹‰é¸å–®",
    "radio": "å–®é¸æŒ‰éˆ•", 
    "tabs": "æ¨™ç±¤é ",
    "cards": "å¡ç‰‡å¼",
    "grid": "ç¶²æ ¼å¼",
    "list": "åˆ—è¡¨å¼"
}

def init_session_state():
    if 'api_profiles' not in st.session_state:
        try:
            base_profiles = st.secrets.get("api_profiles", {})
        except:
            base_profiles = {}
        
        default_profiles = {
            "é è¨­ Pollinations": {
                'provider': 'Pollinations.ai',
                'api_key': '',
                'base_url': 'https://image.pollinations.ai',
                'validated': True,
                'pollinations_auth_mode': 'å…è²»',
                'pollinations_token': '',
                'pollinations_referrer': ''
            }
        }
        
        st.session_state.api_profiles = base_profiles.copy() if base_profiles else default_profiles
    
    if ('active_profile_name' not in st.session_state or 
        st.session_state.active_profile_name not in st.session_state.api_profiles):
        st.session_state.active_profile_name = (
            list(st.session_state.api_profiles.keys())[0] 
            if st.session_state.api_profiles else ""
        )
    
    defaults = {
        'generation_history': [],
        'favorite_images': [],
        'discovered_models': {},
        'selected_model': None,
        'model_selector_style': 'cards',  # é»˜èªä½¿ç”¨å¡ç‰‡å¼
        'show_model_details': True,
        'filter_category': 'All',
        'filter_quality': 'All',
        'filter_speed': 'All',
        'search_term': '',
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def get_active_config():
    return st.session_state.api_profiles.get(st.session_state.active_profile_name, {})

def get_models_by_category(models: Dict[str, Dict]) -> Dict[str, Dict[str, Dict]]:
    categorized = {}
    for model_id, model_info in models.items():
        category = model_info.get('category', 'Other')
        if category not in categorized:
            categorized[category] = {}
        categorized[category][model_id] = model_info
    
    priority_order = ["FLUX", "Stable Diffusion", "Professional", "Anime", "Style", "Community", "OpenAI", "Other"]
    sorted_categorized = {}
    
    for category in priority_order:
        if category in categorized:
            sorted_categorized[category] = categorized[category]
    
    for category, models in categorized.items():
        if category not in sorted_categorized:
            sorted_categorized[category] = models
    
    return sorted_categorized

def merge_models() -> Dict[str, Dict]:
    provider = get_active_config().get('provider')
    discovered = st.session_state.get('discovered_models', {})
    
    if provider in API_PROVIDERS:
        hardcoded = API_PROVIDERS[provider].get('hardcoded_models', {})
        merged = {**hardcoded, **discovered}
    else:
        merged = discovered
    
    return merged

def filter_models(models: Dict[str, Dict]) -> Dict[str, Dict]:
    """æ ¹æ“šéæ¿¾æ¢ä»¶ç¯©é¸æ¨¡å‹"""
    filtered = {}
    
    for model_id, model_info in models.items():
        # é¡åˆ¥éæ¿¾
        if (st.session_state.filter_category != 'All' and 
            model_info.get('category', 'Other') != st.session_state.filter_category):
            continue
            
        # è³ªé‡éæ¿¾
        if (st.session_state.filter_quality != 'All' and 
            model_info.get('quality', 'ä¸­') != st.session_state.filter_quality):
            continue
            
        # é€Ÿåº¦éæ¿¾
        if (st.session_state.filter_speed != 'All' and 
            model_info.get('speed', 'ä¸­') != st.session_state.filter_speed):
            continue
            
        # æœç´¢éæ¿¾
        if st.session_state.search_term:
            search_lower = st.session_state.search_term.lower()
            if not any([
                search_lower in model_id.lower(),
                search_lower in model_info.get('name', '').lower(),
                search_lower in model_info.get('description', '').lower(),
                search_lower in model_info.get('category', '').lower()
            ]):
                continue
        
        filtered[model_id] = model_info
    
    return filtered

def show_model_filters(models: Dict[str, Dict]):
    """é¡¯ç¤ºæ¨¡å‹éæ¿¾å™¨"""
    st.subheader("ğŸ” æ¨¡å‹ç¯©é¸")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # é¡åˆ¥éæ¿¾
        categories = ['All'] + list(set(m.get('category', 'Other') for m in models.values()))
        st.session_state.filter_category = st.selectbox(
            "é¡åˆ¥", categories, 
            index=categories.index(st.session_state.filter_category) if st.session_state.filter_category in categories else 0,
            key="category_filter"
        )
    
    with col2:
        # è³ªé‡éæ¿¾
        qualities = ['All', 'æœ€é«˜', 'é«˜', 'ä¸­']
        st.session_state.filter_quality = st.selectbox(
            "è³ªé‡", qualities,
            index=qualities.index(st.session_state.filter_quality) if st.session_state.filter_quality in qualities else 0,
            key="quality_filter"
        )
    
    with col3:
        # é€Ÿåº¦éæ¿¾
        speeds = ['All', 'å¿«', 'ä¸­', 'æ…¢']
        st.session_state.filter_speed = st.selectbox(
            "é€Ÿåº¦", speeds,
            index=speeds.index(st.session_state.filter_speed) if st.session_state.filter_speed in speeds else 0,
            key="speed_filter"
        )
    
    with col4:
        # æœç´¢æ¡†
        st.session_state.search_term = st.text_input(
            "æœç´¢æ¨¡å‹",
            value=st.session_state.search_term,
            placeholder="è¼¸å…¥æ¨¡å‹åç¨±æˆ–é—œéµè©...",
            key="model_search"
        )

def get_quality_color(quality: str) -> str:
    """æ ¹æ“šè³ªé‡è¿”å›é¡è‰²"""
    colors = {
        'æœ€é«˜': '#FF6B6B',
        'é«˜': '#4ECDC4', 
        'ä¸­': '#45B7D1',
        'ä½': '#96CEB4'
    }
    return colors.get(quality, '#DDDDDD')

def get_speed_color(speed: str) -> str:
    """æ ¹æ“šé€Ÿåº¦è¿”å›é¡è‰²"""
    colors = {
        'å¿«': '#2ECC71',
        'ä¸­': '#F39C12',
        'æ…¢': '#E74C3C'
    }
    return colors.get(speed, '#DDDDDD')

def show_model_card(model_id: str, model_info: Dict, is_selected: bool = False):
    """é¡¯ç¤ºæ¨¡å‹å¡ç‰‡"""
    quality_color = get_quality_color(model_info.get('quality', 'ä¸­'))
    speed_color = get_speed_color(model_info.get('speed', 'ä¸­'))
    
    # å¡ç‰‡æ¨£å¼
    border_style = "border: 2px solid #FF6B6B;" if is_selected else "border: 1px solid #DDDDDD;"
    
    card_html = f"""
    <div style="
        {border_style}
        border-radius: 10px;
        padding: 15px;
        margin: 5px;
        background: {'#FFF8F8' if is_selected else '#FFFFFF'};
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        cursor: pointer;
        transition: all 0.3s;
    ">
        <div style="display: flex; align-items: center; margin-bottom: 10px;">
            <span style="font-size: 24px; margin-right: 10px;">{model_info.get('icon', 'ğŸ¤–')}</span>
            <h4 style="margin: 0; color: #333;">{model_info.get('name', model_id)}</h4>
        </div>
        
        <div style="margin-bottom: 10px;">
            <span style="
                background-color: {quality_color};
                color: white;
                padding: 2px 8px;
                border-radius: 12px;
                font-size: 12px;
                margin-right: 5px;
            ">è³ªé‡: {model_info.get('quality', 'ä¸­')}</span>
            
            <span style="
                background-color: {speed_color};
                color: white;
                padding: 2px 8px;
                border-radius: 12px;
                font-size: 12px;
            ">é€Ÿåº¦: {model_info.get('speed', 'ä¸­')}</span>
        </div>
        
        <p style="
            color: #666;
            font-size: 14px;
            margin: 0;
            line-height: 1.4;
        ">{model_info.get('description', 'æš«ç„¡æè¿°')}</p>
        
        <div style="
            margin-top: 10px;
            padding-top: 10px;
            border-top: 1px solid #EEEEEE;
            color: #888;
            font-size: 12px;
        ">
            é¡åˆ¥: {model_info.get('category', 'Other')}
        </div>
    </div>
    """
    
    return card_html

def show_model_selector_dropdown(models: Dict[str, Dict]) -> Optional[str]:
    """ä¸‹æ‹‰é¸å–®æ¨¡å‹é¸æ“‡å™¨"""
    if not models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None
        
    model_options = list(models.keys())
    model_names = [f"{models[mid].get('icon', 'ğŸ¤–')} {models[mid].get('name', mid)}" for mid in model_options]
    
    current_index = 0
    if st.session_state.selected_model in models:
        current_index = model_options.index(st.session_state.selected_model)
    
    selected_index = st.selectbox(
        "é¸æ“‡æ¨¡å‹",
        range(len(model_options)),
        index=current_index,
        format_func=lambda x: model_names[x],
        key="model_dropdown"
    )
    
    selected_model = model_options[selected_index]
    
    # é¡¯ç¤ºé¸ä¸­æ¨¡å‹çš„è©³ç´°ä¿¡æ¯
    if st.session_state.show_model_details:
        model_info = models[selected_model]
        st.info(f"""
        **{model_info.get('name', selected_model)}**
        
        ğŸ“Š è³ªé‡: {model_info.get('quality', 'ä¸­')} | âš¡ é€Ÿåº¦: {model_info.get('speed', 'ä¸­')}
        
        ğŸ“ {model_info.get('description', 'æš«ç„¡æè¿°')}
        """)
    
    return selected_model

def show_model_selector_radio(models: Dict[str, Dict]) -> Optional[str]:
    """å–®é¸æŒ‰éˆ•æ¨¡å‹é¸æ“‡å™¨"""
    categorized_models = get_models_by_category(models)
    
    selected_model = None
    
    for category, category_models in categorized_models.items():
        st.subheader(f"ğŸ“ {category}")
        
        model_options = list(category_models.keys())
        model_names = [f"{category_models[mid].get('icon', 'ğŸ¤–')} {category_models[mid].get('name', mid)}" for mid in model_options]
        
        current_selection = None
        if st.session_state.selected_model in category_models:
            current_selection = st.session_state.selected_model
        
        choice = st.radio(
            f"{category} æ¨¡å‹",
            model_options,
            index=model_options.index(current_selection) if current_selection else None,
            format_func=lambda x: f"{category_models[x].get('icon', 'ğŸ¤–')} {category_models[x].get('name', x)}",
            key=f"radio_{category}",
            label_visibility="collapsed"
        )
        
        if choice:
            selected_model = choice
    
    return selected_model

def show_model_selector_tabs(models: Dict[str, Dict]) -> Optional[str]:
    """æ¨™ç±¤é æ¨¡å‹é¸æ“‡å™¨"""
    categorized_models = get_models_by_category(models)
    
    if not categorized_models:
        return None
    
    tab_names = list(categorized_models.keys())
    tabs = st.tabs([f"{cat} ({len(categorized_models[cat])})" for cat in tab_names])
    
    selected_model = None
    
    for i, (category, category_models) in enumerate(categorized_models.items()):
        with tabs[i]:
            cols = st.columns(min(3, len(category_models)))
            
            for j, (model_id, model_info) in enumerate(category_models.items()):
                col = cols[j % len(cols)]
                
                with col:
                    is_selected = st.session_state.selected_model == model_id
                    
                    if st.button(
                        f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', model_id)}",
                        key=f"tab_btn_{model_id}",
                        type="primary" if is_selected else "secondary",
                        use_container_width=True
                    ):
                        selected_model = model_id
                        st.session_state.selected_model = model_id
                        rerun_app()
                    
                    if st.session_state.show_model_details:
                        st.caption(f"è³ªé‡: {model_info.get('quality', 'ä¸­')} | é€Ÿåº¦: {model_info.get('speed', 'ä¸­')}")
                        st.caption(model_info.get('description', 'æš«ç„¡æè¿°')[:50] + '...')
    
    return st.session_state.selected_model

def show_model_selector_cards(models: Dict[str, Dict]) -> Optional[str]:
    """å¡ç‰‡å¼æ¨¡å‹é¸æ“‡å™¨"""
    if not models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None
    
    # æŒ‰é¡åˆ¥åˆ†çµ„
    categorized_models = get_models_by_category(models)
    
    selected_model = st.session_state.selected_model
    
    for category, category_models in categorized_models.items():
        st.subheader(f"ğŸ“ {category} ({len(category_models)} å€‹æ¨¡å‹)")
        
        # å‰µå»ºç¶²æ ¼å¸ƒå±€
        cols = st.columns(min(3, len(category_models)))
        
        for i, (model_id, model_info) in enumerate(category_models.items()):
            col = cols[i % len(cols)]
            
            with col:
                is_selected = st.session_state.selected_model == model_id
                
                # é¡¯ç¤ºå¡ç‰‡
                card_html = show_model_card(model_id, model_info, is_selected)
                st.markdown(card_html, unsafe_allow_html=True)
                
                # é¸æ“‡æŒ‰éˆ•
                if st.button(
                    "âœ“ å·²é¸æ“‡" if is_selected else "é¸æ“‡æ­¤æ¨¡å‹",
                    key=f"card_btn_{model_id}",
                    type="primary" if is_selected else "secondary",
                    use_container_width=True
                ):
                    selected_model = model_id
                    st.session_state.selected_model = model_id
                    rerun_app()
    
    return selected_model

def show_model_selector_grid(models: Dict[str, Dict]) -> Optional[str]:
    """ç¶²æ ¼å¼æ¨¡å‹é¸æ“‡å™¨"""
    if not models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None
    
    # å‰µå»ºçµ±ä¸€ç¶²æ ¼
    models_list = list(models.items())
    cols_per_row = 4
    
    selected_model = st.session_state.selected_model
    
    for i in range(0, len(models_list), cols_per_row):
        cols = st.columns(cols_per_row)
        
        for j in range(cols_per_row):
            if i + j < len(models_list):
                model_id, model_info = models_list[i + j]
                
                with cols[j]:
                    is_selected = st.session_state.selected_model == model_id
                    
                    # ç°¡åŒ–çš„å¡ç‰‡
                    st.markdown(f"""
                    <div style="
                        border: {'2px solid #FF6B6B' if is_selected else '1px solid #DDDDDD'};
                        border-radius: 8px;
                        padding: 10px;
                        text-align: center;
                        background: {'#FFF8F8' if is_selected else '#FFFFFF'};
                    ">
                        <div style="font-size: 32px;">{model_info.get('icon', 'ğŸ¤–')}</div>
                        <div style="font-weight: bold; margin: 5px 0;">{model_info.get('name', model_id)[:15]}{'...' if len(model_info.get('name', model_id)) > 15 else ''}</div>
                        <div style="font-size: 12px; color: #666;">{model_info.get('category', 'Other')}</div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if st.button(
                        "âœ“" if is_selected else "é¸æ“‡",
                        key=f"grid_btn_{model_id}",
                        type="primary" if is_selected else "secondary",
                        use_container_width=True
                    ):
                        selected_model = model_id
                        st.session_state.selected_model = model_id
                        rerun_app()
    
    return selected_model

def show_model_selector_list(models: Dict[str, Dict]) -> Optional[str]:
    """åˆ—è¡¨å¼æ¨¡å‹é¸æ“‡å™¨"""
    if not models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None
    
    selected_model = st.session_state.selected_model
    
    # æŒ‰é¡åˆ¥åˆ†çµ„é¡¯ç¤º
    categorized_models = get_models_by_category(models)
    
    for category, category_models in categorized_models.items():
        with st.expander(f"ğŸ“ {category} ({len(category_models)} å€‹æ¨¡å‹)", expanded=True):
            for model_id, model_info in category_models.items():
                is_selected = st.session_state.selected_model == model_id
                
                col1, col2, col3 = st.columns([1, 3, 1])
                
                with col1:
                    st.markdown(f"<div style='font-size: 24px; text-align: center;'>{model_info.get('icon', 'ğŸ¤–')}</div>", unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    **{model_info.get('name', model_id)}**
                    
                    è³ªé‡: {model_info.get('quality', 'ä¸­')} | é€Ÿåº¦: {model_info.get('speed', 'ä¸­')}
                    
                    {model_info.get('description', 'æš«ç„¡æè¿°')}
                    """)
                
                with col3:
                    if st.button(
                        "âœ“ å·²é¸æ“‡" if is_selected else "é¸æ“‡",
                        key=f"list_btn_{model_id}",
                        type="primary" if is_selected else "secondary",
                        use_container_width=True
                    ):
                        selected_model = model_id
                        st.session_state.selected_model = model_id
                        rerun_app()
                
                if model_id != list(category_models.keys())[-1]:
                    st.divider()
    
    return selected_model

def show_model_selector(all_models: Dict[str, Dict]) -> Optional[str]:
    """çµ±ä¸€çš„æ¨¡å‹é¸æ“‡å™¨å…¥å£"""
    if not all_models:
        st.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹ã€‚è«‹åœ¨å´é‚Šæ¬„é…ç½®APIã€‚")
        return None
    
    # é¸æ“‡å™¨æ¨£å¼é…ç½®
    st.subheader("ğŸ›ï¸ æ¨¡å‹é¸æ“‡å™¨è¨­ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.session_state.model_selector_style = st.selectbox(
            "é¸æ“‡å™¨æ¨£å¼",
            list(MODEL_SELECTOR_STYLES.keys()),
            format_func=lambda x: MODEL_SELECTOR_STYLES[x],
            index=list(MODEL_SELECTOR_STYLES.keys()).index(st.session_state.model_selector_style),
            key="selector_style"
        )
    
    with col2:
        st.session_state.show_model_details = st.checkbox(
            "é¡¯ç¤ºæ¨¡å‹è©³ç´°ä¿¡æ¯",
            value=st.session_state.show_model_details,
            key="show_details"
        )
    
    # éæ¿¾å™¨
    show_model_filters(all_models)
    
    # æ‡‰ç”¨éæ¿¾å™¨
    filtered_models = filter_models(all_models)
    
    if not filtered_models:
        st.warning("ğŸ” æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ¨¡å‹ï¼Œè«‹èª¿æ•´ç¯©é¸æ¢ä»¶ã€‚")
        return st.session_state.selected_model
    
    st.markdown("---")
    
    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
    st.caption(f"ğŸ“Š é¡¯ç¤º {len(filtered_models)} / {len(all_models)} å€‹æ¨¡å‹")
    
    # æ ¹æ“šé¸æ“‡çš„æ¨£å¼é¡¯ç¤ºæ¨¡å‹é¸æ“‡å™¨
    if st.session_state.model_selector_style == "dropdown":
        return show_model_selector_dropdown(filtered_models)
    elif st.session_state.model_selector_style == "radio":
        return show_model_selector_radio(filtered_models)
    elif st.session_state.model_selector_style == "tabs":
        return show_model_selector_tabs(filtered_models)
    elif st.session_state.model_selector_style == "cards":
        return show_model_selector_cards(filtered_models)
    elif st.session_state.model_selector_style == "grid":
        return show_model_selector_grid(filtered_models)
    elif st.session_state.model_selector_style == "list":
        return show_model_selector_list(filtered_models)
    else:
        return show_model_selector_cards(filtered_models)  # é»˜èªä½¿ç”¨å¡ç‰‡å¼

# å…¶é¤˜å‡½æ•¸ä¿æŒä¸è®Šï¼ˆç”Ÿæˆã€æ­·å²ç®¡ç†ç­‰ï¼‰
def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    try:
        if provider == "Pollinations.ai":
            return True, "Pollinations.ai ç„¡éœ€é©—è­‰"
        elif provider == "Hugging Face":
            if not api_key:
                return False, "Hugging Face éœ€è¦ API Token"
            headers = {"Authorization": f"Bearer {api_key}"}
            response = requests.get(f"{base_url}/models", headers=headers, timeout=10)
            if response.status_code == 200:
                return True, "Hugging Face API Token é©—è­‰æˆåŠŸ"
            else:
                return False, f"Hugging Face API é©—è­‰å¤±æ•—: {response.status_code}"
        else:
            client = OpenAI(api_key=api_key, base_url=base_url)
            client.models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e:
        return False, f"API é©—è­‰å¤±æ•—: {str(e)[:100]}"

def generate_images_with_retry(client, **params) -> Tuple[bool, any]:
    provider = get_active_config().get('provider')
    n_images = params.get("n", 1)
    
    if provider == "Pollinations.ai":
        return generate_pollinations_images(params, n_images)
    elif provider == "Hugging Face":
        return generate_huggingface_images(params, n_images)
    else:
        return generate_openai_compatible_images(client, params, n_images)

def generate_pollinations_images(params: Dict, n_images: int) -> Tuple[bool, any]:
    generated_images = []
    cfg = get_active_config()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(n_images):
        try:
            status_text.text(f"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{n_images} å¼µåœ–ç‰‡...")
            progress_bar.progress(i / n_images)
            
            current_params = params.copy()
            current_params["seed"] = random.randint(0, 2**32 - 1)
            
            prompt = current_params.get("prompt", "")
            if neg_prompt := current_params.get("negative_prompt"):
                prompt += f" --no {neg_prompt}"
            
            width, height = str(current_params.get("size", "1024x1024")).split('x')
            
            api_params = {}
            for key, value in {
                "model": current_params.get("model"),
                "width": width,
                "height": height,
                "seed": current_params.get("seed"),
                "nologo": current_params.get("nologo"),
                "private": current_params.get("private"),
                "enhance": current_params.get("enhance"),
                "safe": current_params.get("safe")
            }.items():
                if value is not None:
                    api_params[key] = value
            
            headers = {}
            auth_mode = cfg.get('pollinations_auth_mode', 'å…è²»')
            
            if auth_mode == 'ä»¤ç‰Œ' and cfg.get('pollinations_token'):
                headers['Authorization'] = f"Bearer {cfg['pollinations_token']}"
            elif auth_mode == 'åŸŸå' and cfg.get('pollinations_referrer'):
                headers['Referer'] = cfg['pollinations_referrer']
            
            url = f"{cfg['base_url']}/prompt/{quote(prompt)}?{urlencode(api_params)}"
            response = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
            
            if response.ok:
                b64_json = base64.b64encode(response.content).decode()
                image_obj = type('Image', (object,), {'b64_json': b64_json})
                generated_images.append(image_obj)
            else:
                st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆå¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {str(e)[:100]}")
            continue
    
    progress_bar.progress(1.0)
    status_text.text(f"å®Œæˆç”Ÿæˆ {len(generated_images)}/{n_images} å¼µåœ–ç‰‡")
    time.sleep(1)
    progress_bar.empty()
    status_text.empty()
    
    if generated_images:
        response_obj = type('Response', (object,), {'data': generated_images})
        return True, response_obj
    else:
        return False, "æ‰€æœ‰åœ–ç‰‡ç”Ÿæˆå‡å¤±æ•—"

def generate_huggingface_images(params: Dict, n_images: int) -> Tuple[bool, any]:
    generated_images = []
    cfg = get_active_config()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(n_images):
        try:
            status_text.text(f"æ­£åœ¨é€šéHFç”Ÿæˆç¬¬ {i+1}/{n_images} å¼µåœ–ç‰‡...")
            progress_bar.progress(i / n_images)
            
            headers = {"Authorization": f"Bearer {cfg['api_key']}"}
            model = params.get("model")
            prompt = params.get("prompt", "")
            
            payload = {
                "inputs": prompt,
                "parameters": {
                    "negative_prompt": params.get("negative_prompt", ""),
                    "num_inference_steps": 25,
                    "guidance_scale": 7.5,
                }
            }
            
            url = f"{cfg['base_url']}/models/{model}"
            response = requests.post(url, headers=headers, json=payload, timeout=REQUEST_TIMEOUT)
            
            if response.ok:
                b64_json = base64.b64encode(response.content).decode()
                image_obj = type('Image', (object,), {'b64_json': b64_json})
                generated_images.append(image_obj)
            else:
                st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”Ÿæˆå¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"ç¬¬ {i+1} å¼µåœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {str(e)[:100]}")
            continue
    
    progress_bar.progress(1.0)
    status_text.text(f"å®Œæˆç”Ÿæˆ {len(generated_images)}/{n_images} å¼µåœ–ç‰‡")
    time.sleep(1)
    progress_bar.empty()
    status_text.empty()
    
    if generated_images:
        response_obj = type('Response', (object,), {'data': generated_images})
        return True, response_obj
    else:
        return False, "æ‰€æœ‰åœ–ç‰‡ç”Ÿæˆå‡å¤±æ•—"

def generate_openai_compatible_images(client, params: Dict, n_images: int) -> Tuple[bool, any]:
    try:
        sdk_params = {
            "model": params.get("model"),
            "prompt": params.get("prompt"),
            "size": str(params.get("size")),
            "n": n_images,
            "response_format": "b64_json"
        }
        
        if params.get("negative_prompt"):
            sdk_params["negative_prompt"] = params.get("negative_prompt")
        
        sdk_params = {k: v for k, v in sdk_params.items() if v is not None and v != ""}
        return True, client.images.generate(**sdk_params)
    except Exception as e:
        return False, str(e)[:200]

def add_to_history(prompt: str, negative_prompt: str, model: str, images: List[str], metadata: Dict):
    history = st.session_state.generation_history
    new_entry = {
        "id": str(uuid.uuid4()),
        "timestamp": datetime.datetime.now(),
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "model": model,
        "images": images,
        "metadata": metadata
    }
    history.insert(0, new_entry)
    st.session_state.generation_history = history[:MAX_HISTORY_ITEMS]

def display_image_with_actions(b64_json: str, image_id: str, history_item: Dict):
    try:
        img_data = base64.b64decode(b64_json)
        img = Image.open(BytesIO(img_data))
        st.image(img, use_container_width=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰",
                img_data,
                f"ai_generated_{image_id}.png",
                "image/png",
                key=f"dl_{image_id}",
                use_container_width=True
            )
        
        with col2:
            is_fav = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button(
                "â­" if is_fav else "â˜†",
                key=f"fav_{image_id}",
                use_container_width=True,
                help="æ”¶è—/å–æ¶ˆæ”¶è—"
            ):
                if is_fav:
                    st.session_state.favorite_images = [
                        f for f in st.session_state.favorite_images
                        if f['id'] != image_id
                    ]
                else:
                    if len(st.session_state.favorite_images) < MAX_FAVORITE_ITEMS:
                        st.session_state.favorite_images.append({
                            "id": image_id,
                            "image_b64": b64_json,
                            "timestamp": datetime.datetime.now(),
                            "history_item": history_item
                        })
                    else:
                        st.warning(f"æ”¶è—å·²é”ä¸Šé™ ({MAX_FAVORITE_ITEMS})")
                rerun_app()
        
        with col3:
            if st.button(
                "ğŸ¨ è®Šé«”",
                key=f"vary_{image_id}",
                use_container_width=True,
                help="ä½¿ç”¨æ­¤æç¤ºç”Ÿæˆè®Šé«”"
            ):
                st.session_state.update({
                    'vary_prompt': history_item['prompt'],
                    'vary_negative_prompt': history_item.get('negative_prompt', ''),
                    'vary_model': history_item['model']
                })
                rerun_app()
                
    except Exception as e:
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {str(e)[:100]}")

def init_api_client():
    cfg = get_active_config()
    if (cfg and cfg.get('api_key') and cfg.get('provider') not in ["Pollinations.ai", "Hugging Face"]):
        try:
            return OpenAI(api_key=cfg['api_key'], base_url=cfg['base_url'])
        except Exception:
            return None
    return None

def main():
    init_session_state()
    client = init_api_client()
    cfg = get_active_config()
    api_configured = cfg and cfg.get('validated', False)
    
    # å´é‚Šæ¬„
    with st.sidebar:
        st.subheader("âš™ï¸ API è¨­ç½®")
        
        if api_configured:
            provider_info = API_PROVIDERS.get(cfg['provider'], {})
            st.success(f"ğŸŸ¢ å·²é€£æ¥: {st.session_state.active_profile_name}")
            st.info(f"{provider_info.get('icon', 'ğŸ¤–')} {provider_info.get('name', cfg['provider'])}")
        else:
            st.warning("âš ï¸ è«‹é…ç½®APIä¾›æ‡‰å•†")
        
        st.markdown("---")
        st.info(f"""
        **ğŸ“Š çµ±è¨ˆä¿¡æ¯**
        - æ­·å²: {len(st.session_state.generation_history)}/{MAX_HISTORY_ITEMS}
        - æ”¶è—: {len(st.session_state.favorite_images)}/{MAX_FAVORITE_ITEMS}
        - æ‰¹æ¬¡ä¸Šé™: {MAX_BATCH_SIZE}
        """)
    
    # ä¸»æ¨™é¡Œ
    st.title(APP_TITLE)
    st.caption(f"æ”¹é€²çš„æ¨¡å‹é¸æ“‡é«”é©— | {VERSION}")
    
    # ä¸»ç•Œé¢
    tab1, tab2, tab3 = st.tabs([
        "ğŸš€ ç”Ÿæˆåœ–åƒ",
        f"ğŸ“š æ­·å² ({len(st.session_state.generation_history)})",
        f"â­ æ”¶è— ({len(st.session_state.favorite_images)})"
    ])
    
    with tab1:
        if not api_configured:
            st.warning("âš ï¸ è«‹åœ¨å´é‚Šæ¬„é…ç½®ä¸¦é©—è­‰APIä¾›æ‡‰å•†")
        else:
            all_models = merge_models()
            selected_model = show_model_selector(all_models)
            
            if selected_model:
                st.markdown("---")
                
                # ç”Ÿæˆåƒæ•¸
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    selected_style = st.selectbox(
                        "ğŸ¨ é¢¨æ ¼é è¨­",
                        list(STYLE_PRESETS.keys())
                    )
                    
                    prompt_val = st.text_area(
                        "âœï¸ æç¤ºè©",
                        value=st.session_state.pop('vary_prompt', ''),
                        height=120,
                        placeholder="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„åœ–åƒ..."
                    )
                    
                    neg_preset = st.selectbox(
                        "ğŸš« è² å‘æç¤ºè©é è¨­",
                        list(NEGATIVE_PROMPTS.keys())
                    )
                    
                    negative_prompt_val = st.text_area(
                        "ğŸš« è² å‘æç¤ºè©",
                        value=st.session_state.pop('vary_negative_prompt', '') or NEGATIVE_PROMPTS.get(neg_preset, ""),
                        height=80,
                        placeholder="ä¸æƒ³è¦çš„å…§å®¹..."
                    )
                
                with col2:
                    n_images = st.slider(
                        "ğŸ–¼ï¸ ç”Ÿæˆæ•¸é‡",
                        1, MAX_BATCH_SIZE, 1
                    )
                    
                    size_preset = st.selectbox(
                        "ğŸ“ åœ–åƒå°ºå¯¸",
                        options=list(IMAGE_SIZES.keys()),
                        format_func=lambda x: IMAGE_SIZES[x]
                    )
                    
                    if size_preset == "è‡ªå®šç¾©...":
                        col_w, col_h = st.columns(2)
                        with col_w:
                            width = st.slider("å¯¬åº¦", 256, 2048, 1024, 64)
                        with col_h:
                            height = st.slider("é«˜åº¦", 256, 2048, 1024, 64)
                        final_size_str = f"{width}x{height}"
                    else:
                        final_size_str = size_preset
                
                # é«˜ç´šé¸é …
                advanced_options = {}
                if cfg.get('provider') == "Pollinations.ai":
                    with st.expander("ğŸŒ¸ Pollinations.ai é€²éšé¸é …"):
                        col1, col2 = st.columns(2)
                        with col1:
                            advanced_options['enhance'] = st.checkbox("âœ¨ å¢å¼·æç¤ºè©", True)
                            advanced_options['private'] = st.checkbox("ğŸ”’ ç§å¯†æ¨¡å¼", True)
                        with col2:
                            advanced_options['nologo'] = st.checkbox("ğŸš« ç§»é™¤æ¨™èªŒ", True)
                            advanced_options['safe'] = st.checkbox("ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼", False)
                
                # ç”ŸæˆæŒ‰éˆ•
                if st.button(
                    "ğŸš€ ç”Ÿæˆåœ–åƒ",
                    type="primary",
                    use_container_width=True,
                    disabled=not prompt_val.strip()
                ):
                    final_prompt = prompt_val
                    if selected_style != "ç„¡" and STYLE_PRESETS[selected_style]:
                        final_prompt = f"{final_prompt}, {STYLE_PRESETS[selected_style]}"
                    
                    params = {
                        "model": selected_model,
                        "prompt": final_prompt,
                        "negative_prompt": negative_prompt_val,
                        "size": final_size_str,
                        "n": n_images,
                        **advanced_options
                    }
                    
                    model_name = all_models[selected_model]['name']
                    with st.spinner(f"ğŸ¨ æ­£åœ¨ä½¿ç”¨ {model_name} ç”Ÿæˆ {n_images} å¼µåœ–åƒ..."):
                        success, result = generate_images_with_retry(client, **params)
                    
                    if success and hasattr(result, 'data') and result.data:
                        img_b64s = [img.b64_json for img in result.data]
                        
                        add_to_history(
                            prompt_val,
                            negative_prompt_val,
                            selected_model,
                            img_b64s,
                            {
                                "size": final_size_str,
                                "provider": cfg['provider'],
                                "style": selected_style,
                                "n": n_images,
                                "model_name": model_name
                            }
                        )
                        
                        st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(img_b64s)} å¼µåœ–åƒï¼")
                        
                        if len(img_b64s) == 1:
                            display_image_with_actions(
                                img_b64s[0],
                                f"{st.session_state.generation_history[0]['id']}_0",
                                st.session_state.generation_history[0]
                            )
                        else:
                            cols = st.columns(2)
                            for i, b64_json in enumerate(img_b64s):
                                with cols[i % 2]:
                                    display_image_with_actions(
                                        b64_json,
                                        f"{st.session_state.generation_history[0]['id']}_{i}",
                                        st.session_state.generation_history[0]
                                    )
                        
                        gc.collect()
                    else:
                        st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")
    
    with tab2:
        if not st.session_state.generation_history:
            st.info("ğŸ“­ é‚„æ²’æœ‰ç”Ÿæˆæ­·å²ã€‚")
        else:
            for item in st.session_state.generation_history:
                timestamp_str = item['timestamp'].strftime('%m-%d %H:%M')
                all_models = merge_models()
                model_info = all_models.get(item['model'], {})
                model_name = model_info.get('name', item['model'])
                
                with st.expander(f"ğŸ¨ {item['prompt'][:60]}... | {model_name} | {timestamp_str}"):
                    st.markdown(f"**âœï¸ æç¤ºè©:** {item['prompt']}")
                    if item.get('negative_prompt'):
                        st.markdown(f"**ğŸš« è² å‘æç¤ºè©:** {item['negative_prompt']}")
                    
                    if len(item['images']) == 1:
                        display_image_with_actions(
                            item['images'][0],
                            f"hist_{item['id']}_0",
                            item
                        )
                    else:
                        cols = st.columns(2)
                        for i, b64_json in enumerate(item['images']):
                            with cols[i % 2]:
                                display_image_with_actions(
                                    b64_json,
                                    f"hist_{item['id']}_{i}",
                                    item
                                )
    
    with tab3:
        if not st.session_state.favorite_images:
            st.info("â­ é‚„æ²’æœ‰æ”¶è—çš„åœ–åƒã€‚")
        else:
            sorted_favorites = sorted(
                st.session_state.favorite_images,
                key=lambda x: x['timestamp'],
                reverse=True
            )
            
            cols = st.columns(3)
            for i, fav in enumerate(sorted_favorites):
                with cols[i % 3]:
                    display_image_with_actions(
                        fav['image_b64'],
                        fav['id'],
                        fav.get('history_item', {})
                    )
                    
                    fav_time = fav['timestamp'].strftime('%m-%d %H:%M')
                    st.caption(f"â­ æ”¶è—æ–¼: {fav_time}")
    
    # é è…³
    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; color: #888; margin-top: 2rem;">
        <small>
            ğŸ¨ <strong>AI åœ–åƒç”Ÿæˆå™¨ {VERSION}</strong> | 
            æ”¹é€²çš„æ¨¡å‹é¸æ“‡é«”é©— | 
            è®“å‰µæ„ç„¡é™å»¶ä¼¸ ğŸ¨
        </small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
